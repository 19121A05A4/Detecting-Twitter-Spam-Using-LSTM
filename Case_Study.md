# ðŸ“„ Case Study: Twitter Spam Detection using LSTM (Encoder-Decoder to Classifier Evolution)

## ðŸ§  Overview

This case study explores the design and evolution of a Twitter Spam Detection system, built using deep learning techniques. The system classifies tweets as **Spam** or **Ham (legit)**, using textual features only.

Originally conceived as an encoder-decoder architecture, the project evolved into a more effective LSTM-based binary classifier. This transition significantly improved accuracy, simplified deployment, and helped me understand how architecture selection directly impacts model performance.

---

## ðŸ” Problem Statement

With the rise in bot accounts, scam messages, and promotional spam on Twitter, detecting such messages automatically is essential. The goal is to:
> **Classify a tweet into "Spam" or "Ham" using its raw text**

This task involves:
- Understanding natural language
- Handling short and noisy text (tweets)
- Building a model that generalizes well to unseen examples

---

## ðŸ§ª Phase 1: Encoder-Decoder Model

### ðŸ—ï¸ Architecture
- **Encoder**: LSTM processed tweet input â†’ vector
- **Decoder**: Dense layer attempted to classify from vector

### ðŸ”¬ Observations
- **Accuracy**: ~83â€“91% (Validation)
- **Confidence**: Many outputs hovered around 0.49â€“0.51
- **Confusion Matrix**: Misclassified obvious spam as ham
- **Training/Deployment**: Slow training, hard to debug in layers
- **Conclusion**: Overkill for binary classification

---

## âœ… Phase 2: LSTM Binary Classifier (Final Version)

### ðŸ—ï¸ Architecture
Input â†’ Embedding â†’ LSTM â†’ Dropout â†’ LSTM â†’ Dropout â†’ Dense (sigmoid)


- Input: Preprocessed and padded tweet sequences
- Output: Binary probability
- Optimized for binary crossentropy loss

### ðŸ”¬ Results
- **Validation Accuracy**: 98.3%
- **False Positives**: 0
- **False Negatives**: 19
- **Model Confidence**: High and stable
- **Training Time**: Faster
- **Deployment**: Integrated easily with Streamlit

---

## ðŸ” Model Comparison

| Metric                     | Encoder-Decoder | LSTM Classifier |
|----------------------------|-----------------|------------------|
| Complexity                 | High             | âœ… Simple         |
| Accuracy (Validation)      | ~83â€“91%          | âœ… 98.3%          |
| Training Stability         | âŒ Unstable       | âœ… Stable         |
| Confidence Distribution    | âŒ Narrow range   | âœ… Clear signal   |
| Deployment Feasibility     | âŒ Difficult      | âœ… Easy w/ Streamlit |
| Overfitting Risk           | High             | âœ… Mitigated w/ Dropout |

---

## ðŸ“Š Evaluation Metrics

- Accuracy / Loss curves
- Confusion matrix:
[[965 0] [ 19 106]]


- Classification report:
- F1 Score (Spam): 0.92
- Precision: 1.00
- Recall: 0.85

---

## ðŸŒ Deployment: Streamlit App

To make the project interactive, a **Streamlit web app** was built:
- Enter any tweet
- See real-time prediction and confidence score
- Optionally visualize model performance (confusion matrix, classification report)

---

## ðŸ“š Key Learnings

- Architecture should match task complexity  
- Evaluation > accuracy â€” metrics like recall, F1, confusion matrix matter  
- Simpler models often generalize better in production  
- Deployment (Streamlit) teaches valuable lessons beyond model building  

---

## ðŸ”® Future Enhancements

- Integrate **Twitter API** for live tweet analysis
- Train with **BERT or transformer-based encoders**
- Add **SHAP/LIME explainability** to visualize attention
- Expand dataset with multilingual tweets
- Deploy to **Streamlit Cloud** or **Hugging Face Spaces**

---

## ðŸ‘‹ Final Thoughts

This project taught me the importance of **iterating based on results**, not assumptions. By moving from an encoder-decoder architecture to a streamlined LSTM classifier, I built a spam detection system that performs accurately and is ready for real-world use â€” all wrapped in a beautiful web interface.

> Every experiment taught me something â€” and I now understand not just how to build a model, but when to change one.

---

âœ… [Back to Main Project README](README.md)




